ğŸŒ Projeto IoT â€“ Pipeline de Dados com Docker, PostgreSQL, Python e Streamlit
ğŸ“˜ VisÃ£o Geral

Este projeto foi desenvolvido para a disciplina Disruptive Architectures: IoT, Big Data e IA e tem como objetivo construir um pipeline de dados IoT completo, com coleta, armazenamento, processamento e visualizaÃ§Ã£o de leituras de temperatura geradas por sensores.

O pipeline foi construÃ­do com as seguintes tecnologias:

ğŸ³ Docker + PostgreSQL (banco de dados em container)

ğŸ Python + pandas + SQLAlchemy (ETL e persistÃªncia)

ğŸ§  Views SQL (camada analÃ­tica)

ğŸ“Š Streamlit + Plotly (dashboard interativo)

ğŸ§± Tecnologias Utilizadas
Camada	Ferramentas
Banco de Dados	PostgreSQL + Docker
ETL	Python, pandas, SQLAlchemy
AnÃ¡lises	Views SQL
VisualizaÃ§Ã£o	Streamlit + Plotly
âš™ï¸ Como Executar o Projeto
ğŸ³ 1. Subir o banco PostgreSQL com Docker
docker run --name postgres-iot -e POSTGRES_PASSWORD=sua_senha -p 5432:5432 -d postgres


Caso o container jÃ¡ exista:

docker start postgres-iot


Criar o banco:

docker exec -it postgres-iot psql -U postgres -c "CREATE DATABASE iot_db;"

ğŸ 2. Preparar o ambiente Python
python -m venv venv
.\venv\Scripts\activate   # Windows
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt

ğŸ” 3. Executar o pipeline de ingestÃ£o e criaÃ§Ã£o de views
python src/pipeline.py

ğŸ“Š 4. Rodar o dashboard interativo
streamlit run src/dashboard.py


Acesse no navegador: http://localhost:8501

ğŸ“ Estrutura de Pastas
PI_IV_UNIVESP/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py         # IngestÃ£o de dados e criaÃ§Ã£o das views
â”‚   â””â”€â”€ dashboard.py        # Interface interativa com Streamlit
â”‚
â”œâ”€â”€ sql/                    # Scripts SQL das views criadas
â”‚   â”œâ”€â”€ init.sql
â”‚   â”œâ”€â”€ temp_media...
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ prints-dashboard/   # Capturas de tela do dashboard
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ—‚ï¸ Views SQL Criadas
avg_temp_por_dispositivo
SELECT device_id, AVG(temperature) AS avg_temp
FROM temperature_readings
GROUP BY device_id;


ğŸ“Œ Temperatura mÃ©dia por dispositivo.

leituras_por_hora
SELECT EXTRACT(HOUR FROM timestamp) AS hora, COUNT(*) AS contagem
FROM temperature_readings
GROUP BY hora
ORDER BY hora;


ğŸ“Œ DistribuiÃ§Ã£o de leituras por hora do dia.

temp_max_min_por_dia
SELECT DATE(timestamp) AS data,
       MAX(temperature) AS temp_max,
       MIN(temperature) AS temp_min
FROM temperature_readings
GROUP BY DATE(timestamp)
ORDER BY DATE(timestamp);


ğŸ“Œ Temperaturas mÃ¡xima e mÃ­nima por dia.

ğŸ“Š VisualizaÃ§Ãµes no Dashboard

Temperatura mÃ©dia por dispositivo


Leituras por hora do dia


Temperaturas mÃ¡ximas e mÃ­nimas por dia


MÃ©dia de temperatura por localizaÃ§Ã£o (in/out)


ğŸ” Principais Insights

ğŸŒ¡ï¸ VariaÃ§Ãµes de temperatura entre dispositivos, sugerindo diferenÃ§as ambientais ou calibraÃ§Ã£o.

â° Picos de leitura em horÃ¡rios especÃ­ficos, indicando momentos crÃ­ticos de monitoramento.

ğŸ“ˆ TendÃªncia de mÃ¡ximas e mÃ­nimas diÃ¡rias, com potencial aplicaÃ§Ã£o em agricultura e energia.

ğŸ  DiferenÃ§as claras entre locais internos e externos, importantes para controle climÃ¡tico.

ğŸ“¦ DependÃªncias (requirements.txt)
pandas
sqlalchemy
psycopg2-binary
streamlit
plotly


Instale com:

pip install -r requirements.txt

ğŸ§ª Comandos Git Utilizados
git init
git add .
git commit -m "IoT pipeline: ingestÃ£o, views e dashboard"
git branch -M main
git remote add origin https://github.com/SEU-USUARIO/projeto-iot.git
git push -u origin main

ğŸ”— Dataset de Origem

ğŸ“ Kaggle â€“ Temperature Readings: IoT Devices